{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e14f262",
   "metadata": {},
   "source": [
    "## 梯度下降法进行逻辑回归\n",
    "### 生成逻辑回归的样本数据\n",
    "逻辑回归的函数形式：\n",
    "$Y = f(z)=\\frac{1}{1+e^{z}}, z=\\beta X+\\varepsilon $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf5b75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecbb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a815f35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_classification(n_samples=3200,n_features=4,n_informative=4,n_redundant=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d443bda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[0].T\n",
    "Y = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64c5f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Beta(X,b):#X为X向量，b为β向量\n",
    "    X = np.vstack((1,X.reshape(len(X),1)))\n",
    "    Y = np.dot(b.reshape(1,len(X)),X)\n",
    "    return Y[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49b4906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def random_log(beta_range,x_num,n,x_range,seed,var_epsilon = 1):#生成线性回归数据\\n    np.random.seed(seed)\\n    beta = np.random.uniform(beta_range[0],beta_range[1],x_num+1)\\n    np.random.seed(seed)\\n    x = np.random.uniform(x_range[0],x_range[1],x_num*n)\\n    x = x.reshape(x_num, n)\\n    z = []\\n    for i in range(n):\\n        X = np.array([x[0:,i]]).reshape(x_num, 1)\\n        z.append(Beta(X, beta))\\n    np.random.seed(seed)\\n    epsilon = np.random.normal(0, var_epsilon, n)\\n    z = z + epsilon\\n    Y = np.around(1/(1+np.exp(z)))\\n    return {\"beta\":beta, \"x\":x, \"Y\":Y}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自造逻辑回归样本，效果并不好，考虑是因为X的值过于远离0点，Y值的变化概率很小，导致损失函数的减小的向量过小，无法迭代优化。\n",
    "'''def random_log(beta_range,x_num,n,x_range,seed,var_epsilon = 1):#生成线性回归数据\n",
    "    np.random.seed(seed)\n",
    "    beta = np.random.uniform(beta_range[0],beta_range[1],x_num+1)\n",
    "    np.random.seed(seed)\n",
    "    x = np.random.uniform(x_range[0],x_range[1],x_num*n)\n",
    "    x = x.reshape(x_num, n)\n",
    "    z = []\n",
    "    for i in range(n):\n",
    "        X = np.array([x[0:,i]]).reshape(x_num, 1)\n",
    "        z.append(Beta(X, beta))\n",
    "    np.random.seed(seed)\n",
    "    epsilon = np.random.normal(0, var_epsilon, n)\n",
    "    z = z + epsilon\n",
    "    Y = np.around(1/(1+np.exp(z)))\n",
    "    return {\"beta\":beta, \"x\":x, \"Y\":Y}'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22cfd001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"x = random_log([-5,5], 4, 3200, [-100,100], 431)['x']\\nbeta = random_log([-5,5], 4, 3200, [-100,100], 431)['beta']\\nY = random_log([-5,5], 4, 3200, [-100,100], 431)['Y']\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''x = random_log([-5,5], 4, 3200, [-100,100], 431)['x']\n",
    "beta = random_log([-5,5], 4, 3200, [-100,100], 431)['beta']\n",
    "Y = random_log([-5,5], 4, 3200, [-100,100], 431)['Y']'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c2ab00",
   "metadata": {},
   "source": [
    "### 确定损失函数$J(\\hat{\\beta})$\n",
    "损失函数设为对数极大似然函数的相反数。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bcf84b",
   "metadata": {},
   "source": [
    "极大似然函数：\n",
    "$L(\\hat{\\beta} )=\\prod_{i=1}^{n}p_{0}^{1-y_{i} }p_{1}^{y_{i} }$,\n",
    "    其中p0，p1分别表示$\\hat{y_{i}}$取0和1的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd47ff",
   "metadata": {},
   "source": [
    "$p_{1}=\\frac{1}{1+e^{\\hat{\\beta}X_{i} }} ,p_{0}=1-p_{1}=\\frac{e^{\\hat{\\beta}X_{i}}}{1+e^{\\hat{\\beta}X_{i} }}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce8c156",
   "metadata": {},
   "source": [
    "对数似然函数：$lnL(\\hat{\\beta})=\\sum_{i=1}^{n}ln(p_{0}^{1-y_{i}})+\\sum_{i=1}^{n}ln(p_{1}^{y_{i}})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d315524",
   "metadata": {},
   "source": [
    "$=\\sum_{i=1}^{n}(1-y_{i})ln(e^{\\hat{\\beta}X_{i}})-\\sum_{i=1}^{n}(1-y_{i})ln(1+e^{\\hat{\\beta}X_{i}})-\\sum_{i=1}^{n}y_{i}ln(1+e^{\\hat{\\beta}X_{i}}) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cf9d10",
   "metadata": {},
   "source": [
    "$=\\sum_{i=1}^{n}(1-y_{i})\\hat{\\beta}X_{i}-\\sum_{i=1}^{n}ln(1+e^{\\hat{\\beta }X_{i} })$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f5457d",
   "metadata": {},
   "source": [
    "所以$J(\\hat{\\beta})=-lnL(\\hat{\\beta})=\\sum_{i=1}^{n}ln(1+e^{\\hat{\\beta }X_{i} })-\\sum_{i=1}^{n}(1-y_{i})\\hat{\\beta}X_{i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a0b404",
   "metadata": {},
   "source": [
    "### 对损失函数求$\\hat{\\beta}$的偏导数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33e6f26",
   "metadata": {},
   "source": [
    "$J'(\\hat{\\beta})=\\left\\{\\begin{matrix} \n",
    "  \\sum_{i=1}^{n} (\\frac{e^{\\hat{\\beta}X_{i}}}{1+e^{\\hat{\\beta}X_{i}}} -  1+y_{i}) (对\\beta_{0}求导)\\\\  \n",
    "   \\sum_{i=1}^{n} [X_{ij}(\\frac{e^{\\hat{\\beta}X_{i}}}{1+e^{\\hat{\\beta}X_{i}}} -  1+y_{i})(对\\beta_{j}求导)\n",
    "\\end{matrix}\\right. $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea123989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partical(x, beta_hat, Y):#βhat为估计的β向量\n",
    "    sum0 = []\n",
    "    k = len(x[0:,0])#变量数\n",
    "    n = len(x[0, 0:])#样本数\n",
    "    for i in range(n):\n",
    "        sum0.append(np.exp(Beta(x[0:,i],beta_hat))/(1+np.exp(Beta(x[0:,i],beta_hat))) - 1 + Y[i])\n",
    "    vector0 = sum(sum0)\n",
    "    vector = []\n",
    "    for j in range(k):\n",
    "        vector.append(sum(np.asarray(sum0) * x[j,0:]))\n",
    "    vector = np.hstack((vector0,vector))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fce5710",
   "metadata": {},
   "source": [
    "### 小批量梯度下降法迭代估计$\\beta$的值，并计算auc查看模型拟合效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aa3c939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mngb(x, Y, mini_batch, origin, accuracy, alpha,times_num = 1000000):\n",
    "    col = np.random.randint(len(x[0, 0:]), size = mini_batch)\n",
    "    x0 = x[0: , col]\n",
    "    Y0 = Y[col]\n",
    "    theta = origin - alpha * partical(x0, origin, Y0)\n",
    "    delta = accuracy +1\n",
    "    times = 0\n",
    "    while delta >= accuracy:\n",
    "        times += 1\n",
    "        col = np.random.randint(len(x[0, 0:]), size = mini_batch)\n",
    "        x0 = x[0: , col]\n",
    "        Y0 = Y[col]\n",
    "        theta = theta - alpha * partical(x0, theta, Y0)\n",
    "        delta = alpha * abs(max(partical(x0, theta, Y0)))\n",
    "        if times >= times_num: break\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec5c4e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.85976649  0.92891547  0.73281237 -1.01556071  2.39539702]\n"
     ]
    }
   ],
   "source": [
    "beta_hat = mngb(x, Y, 4, np.array([0, 0, 0, 0, 0]), 1e-8, 1e-3, 100000)\n",
    "print(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5017f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yhat(x,beta):\n",
    "    z = []\n",
    "    for i in range(len(x[0,0:])):\n",
    "        z.append(Beta(x[0:,i],beta))\n",
    "    y = np.around(1/(1+np.exp(z)))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a7d6dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9378036866420651"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = yhat(x,beta_hat)\n",
    "roc_auc_score(Y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0587d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82cec0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6abc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "re = lr.fit(x.T,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "073b51ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = re.score(x.T,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ab17065",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9453125"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94af66f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
